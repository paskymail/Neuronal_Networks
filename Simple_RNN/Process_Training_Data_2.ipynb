{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIdT9iu_Z4Rb"
   },
   "source": [
    "# Process training Data to train a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pprint as pprint\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFh9ne3FZ-On"
   },
   "source": [
    "### 1. Get the data from CSV files\n",
    "First Import it using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_action (class_int):\n",
    "    with open('./data/class_to_action (28).json') as json_file:\n",
    "        CtA = json.load(json_file)\n",
    "        \n",
    "    action = CtA[class_int]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_category(X, pred):\n",
    "    tree = sklearn.neighbors.KDTree(X, leaf_size=2)\n",
    "    dist, ind = tree.query(pred, k=1)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data (file):\n",
    "    raw_dataset = pd.read_csv(file)\n",
    "    dataset = raw_dataset.copy()\n",
    "    training_size = len(dataset)\n",
    "    N_CATEGORIES = 28\n",
    "\n",
    "    dataset[\"A0\"] = np.nan\n",
    "    dataset[\"A1\"] = np.nan\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        CS_array =np.array(eval(row[\"current_state\"]))\n",
    "        dataset[\"current_state\"][index] = CS_array\n",
    "        GS_array =np.array(eval(row[\"goal_state\"]))\n",
    "        dataset[\"goal_state\"][index] = GS_array\n",
    "        GS_array =np.array(eval(row[\"out_action\"]))\n",
    "        dataset[\"out_action\"][index] = GS_array\n",
    "\n",
    "    # Usar estado final \n",
    "    dataset[\"Difference\"] =   dataset[\"goal_state\"]-dataset[\"current_state\"]\n",
    "\n",
    "    dataset[[\"C0\",'C1',\"C2\",\"C3\",'C4',\"C5\"]] = pd.DataFrame(dataset.current_state.values.tolist(), index= dataset.index)\n",
    "    dataset[[\"D0\",'D1',\"D2\",\"D3\",'D4',\"D5\"]] = pd.DataFrame(dataset.Difference.values.tolist(), index= dataset.index)\n",
    "    dataset[[\"A0\",\"A1\"]] = pd.DataFrame(dataset.out_action.values.tolist(), index= dataset.index)\n",
    "    \n",
    "    dataset_short= dataset[[\"id_camino\",\"D0\",'D1',\"D2\",\"D3\",'D4',\"D5\",\"A0\",\"A1\"]]\n",
    "\n",
    "    return dataset_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the last state with the exit action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_dataset(dataset_short):\n",
    "    extended_dataset = dataset_short.copy()\n",
    "    exit_state = pd.DataFrame([{\"id_camino\":0,\"D0\":0,'D1':0,\"D2\":0,\"D3\":0,'D4':0,\"D5\":0,\"A0\":-1,\"A1\":-1}])\n",
    "    for camino in extended_dataset[\"id_camino\"].unique():\n",
    "        exit_state[\"id_camino\"] = camino\n",
    "        extended_dataset.append(exit_state)\n",
    "\n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_short = get_data(\"./data/OSPA_training_data 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id_camino         D0        D1         D2        D3        D4        D5  \\\n",
       "0            0  85.591116 -9.250073  -4.257165  0.000000  0.000000  0.000000   \n",
       "1            0  80.846048 -8.006316  -5.915147 -0.618050  0.228180  0.002423   \n",
       "2            0  74.575747 -7.229901  -5.983671 -0.806063 -0.238873 -0.012752   \n",
       "3            0  68.915460 -6.614438  -6.322726 -0.403866  0.287311  0.014920   \n",
       "4            0  62.080447 -5.388121  -6.883976 -0.744963 -0.154067 -0.013679   \n",
       "..         ...        ...       ...        ...       ...       ...       ...   \n",
       "870         95  40.131874 -9.374105  -7.023492 -0.332507  0.532105  0.011985   \n",
       "871         95  32.593189 -4.096806 -11.197549 -0.327874  0.564534 -0.002736   \n",
       "872         95  21.737242  2.181474 -13.559371 -0.334918  0.420465 -0.005766   \n",
       "873         95   8.765791  4.868894 -12.505681 -0.490775 -0.075725 -0.013592   \n",
       "874         95   0.728507  0.485512  -5.593651 -0.559175 -1.043255 -0.014195   \n",
       "\n",
       "          A0   A1  \n",
       "0   -0.05236  0.0  \n",
       "1   -0.10472  0.0  \n",
       "2   -0.00000  0.0  \n",
       "3   -0.08727  0.0  \n",
       "4   -0.03491  0.0  \n",
       "..       ...  ...  \n",
       "870 -0.01745  0.0  \n",
       "871 -0.01745  0.0  \n",
       "872 -0.03491  0.0  \n",
       "873 -0.08727  0.0  \n",
       "874      NaN  NaN  \n",
       "\n",
       "[875 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_camino</th>\n      <th>D0</th>\n      <th>D1</th>\n      <th>D2</th>\n      <th>D3</th>\n      <th>D4</th>\n      <th>D5</th>\n      <th>A0</th>\n      <th>A1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>85.591116</td>\n      <td>-9.250073</td>\n      <td>-4.257165</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.05236</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>80.846048</td>\n      <td>-8.006316</td>\n      <td>-5.915147</td>\n      <td>-0.618050</td>\n      <td>0.228180</td>\n      <td>0.002423</td>\n      <td>-0.10472</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>74.575747</td>\n      <td>-7.229901</td>\n      <td>-5.983671</td>\n      <td>-0.806063</td>\n      <td>-0.238873</td>\n      <td>-0.012752</td>\n      <td>-0.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>68.915460</td>\n      <td>-6.614438</td>\n      <td>-6.322726</td>\n      <td>-0.403866</td>\n      <td>0.287311</td>\n      <td>0.014920</td>\n      <td>-0.08727</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>62.080447</td>\n      <td>-5.388121</td>\n      <td>-6.883976</td>\n      <td>-0.744963</td>\n      <td>-0.154067</td>\n      <td>-0.013679</td>\n      <td>-0.03491</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>870</th>\n      <td>95</td>\n      <td>40.131874</td>\n      <td>-9.374105</td>\n      <td>-7.023492</td>\n      <td>-0.332507</td>\n      <td>0.532105</td>\n      <td>0.011985</td>\n      <td>-0.01745</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>871</th>\n      <td>95</td>\n      <td>32.593189</td>\n      <td>-4.096806</td>\n      <td>-11.197549</td>\n      <td>-0.327874</td>\n      <td>0.564534</td>\n      <td>-0.002736</td>\n      <td>-0.01745</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>872</th>\n      <td>95</td>\n      <td>21.737242</td>\n      <td>2.181474</td>\n      <td>-13.559371</td>\n      <td>-0.334918</td>\n      <td>0.420465</td>\n      <td>-0.005766</td>\n      <td>-0.03491</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>873</th>\n      <td>95</td>\n      <td>8.765791</td>\n      <td>4.868894</td>\n      <td>-12.505681</td>\n      <td>-0.490775</td>\n      <td>-0.075725</td>\n      <td>-0.013592</td>\n      <td>-0.08727</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>874</th>\n      <td>95</td>\n      <td>0.728507</td>\n      <td>0.485512</td>\n      <td>-5.593651</td>\n      <td>-0.559175</td>\n      <td>-1.043255</td>\n      <td>-0.014195</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>875 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "dataset_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extended_dataset= extend_dataset(dataset_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     id_camino         D0         D1        D2   D3   D4   D5       A0   A1\n0            0  85.591116  -9.250073 -4.257165  0.0  0.0  0.0 -0.05236  0.0\n15           1  98.043500 -37.779358 -4.257165  0.0  0.0  0.0 -0.03491  0.0\n25           2  91.272922 -36.852284 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n34           3  94.839433  -8.007799 -4.257165  0.0  0.0  0.0 -0.05236  0.0\n52           4  69.791783 -31.305606 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n..         ...        ...        ...       ...  ...  ...  ...      ...  ...\n837         91  42.194642 -11.734715 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n843         92  69.165322 -20.503194 -4.257165  0.0  0.0  0.0 -0.03491  0.0\n851         93  68.665098 -10.947339 -4.257165  0.0  0.0  0.0 -0.05236  0.0\n863         94  43.155597 -21.812576 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n869         95  44.965468 -11.330250 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n\n[96 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extended_dataset.loc[extended_dataset[\"D3\"]==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ywmerQ6dSox"
   },
   "source": [
    "It is good practice to normalize features that use different scales and ranges. Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input.\n",
    "\n",
    "Note: Although we intentionally generate these statistics from only the training dataset, these statistics will also be used to normalize the test dataset. We need to do that to project the test dataset into the same distribution that the model has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, train_stats):\n",
    "  #return (x - train_stats['mean']) / train_stats['std']\n",
    "  return (x) / train_stats['std']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x, train_stats):\n",
    "  #return (x - train_stats['mean']) / train_stats['std']\n",
    "  return (x) * train_stats['std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataset_short,action_vector):\n",
    "    reduced_dataset = dataset_short.copy()\n",
    "    reduced_dataset.pop(\"A0\")\n",
    "    reduced_dataset.pop(\"A1\")\n",
    "    reduced_dataset.pop(\"id_camino\")\n",
    "    data_stats = reduced_dataset.describe()\n",
    "    data_stats = data_stats.transpose()\n",
    "\n",
    "    data_stats.to_csv(r\"./data/data_stats2.csv\")\n",
    "\n",
    "    action_vector.append(\"id_camino\")\n",
    "    normed_data = norm(reduced_dataset, data_stats)\n",
    "    normed_dataset = normed_data.join(dataset_short[action_vector])\n",
    "\n",
    "    return normed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(normed_dataset,N_STEPS, position):\n",
    "    PAD_LEN = N_STEPS+1\n",
    "    padded_data = []\n",
    "    for camino in normed_dataset[\"id_camino\"].unique():\n",
    "        group = normed_dataset[normed_dataset[\"id_camino\"]==camino]\n",
    "        group.pop(\"id_camino\")\n",
    "        padded_data.append(group.values)\n",
    "    \n",
    "    dataset2 = tf.keras.preprocessing.sequence.pad_sequences(padded_data, maxlen=PAD_LEN, dtype='float64', padding=position, truncating=position, value=0.0)\n",
    "\n",
    "    return dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuiClDk45eS4"
   },
   "source": [
    "This normalized data is what we will use to train the model.\n",
    "\n",
    "Caution: The statistics used to normalize the inputs here (mean and standard deviation) need to be applied to any other data that is fed to the model.  That includes the test set as well as live data when the model is used in production."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pasky': virtualenv)",
   "name": "python37564bitpaskyvirtualenvdb13efe5d4c0467fbbb744965ba97dd5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}