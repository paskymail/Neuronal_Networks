{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIdT9iu_Z4Rb"
   },
   "source": [
    "# Process training Data to train a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pprint as pprint\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFh9ne3FZ-On"
   },
   "source": [
    "### 1. Get the data from CSV files\n",
    "First Import it using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_action (class_int):\n",
    "    with open('./data/class_to_action (28).json') as json_file:\n",
    "        CtA = json.load(json_file)\n",
    "        \n",
    "    action = CtA[class_int]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_category(X, pred):\n",
    "    tree = sklearn.neighbors.KDTree(X, leaf_size=2)\n",
    "    dist, ind = tree.query(pred, k=1)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data (file):\n",
    "    raw_dataset = pd.read_csv(file)\n",
    "    dataset = raw_dataset.copy()\n",
    "    training_size = len(dataset)\n",
    "    N_CATEGORIES = 28\n",
    "\n",
    "    dataset[\"A0\"] = np.nan\n",
    "    dataset[\"A1\"] = np.nan\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        CS_array =np.array(eval(row[\"current_state\"]))\n",
    "        dataset[\"current_state\"][index] = CS_array\n",
    "        GS_array =np.array(eval(row[\"goal_state\"]))\n",
    "        dataset[\"goal_state\"][index] = GS_array\n",
    "        GS_array =np.array(eval(row[\"out_action\"]))\n",
    "        dataset[\"out_action\"][index] = GS_array\n",
    "\n",
    "    # Usar estado final \n",
    "    dataset[\"Difference\"] =   dataset[\"goal_state\"]-dataset[\"current_state\"]\n",
    "\n",
    "    dataset[[\"C0\",'C1',\"C2\",\"C3\",'C4',\"C5\"]] = pd.DataFrame(dataset.current_state.values.tolist(), index= dataset.index)\n",
    "    dataset[[\"D0\",'D1',\"D2\",\"D3\",'D4',\"D5\"]] = pd.DataFrame(dataset.Difference.values.tolist(), index= dataset.index)\n",
    "    dataset[[\"A0\",\"A1\"]] = pd.DataFrame(dataset.out_action.values.tolist(), index= dataset.index)\n",
    "    \n",
    "    dataset_short= dataset[[\"id_camino\",\"D0\",'D1',\"D2\",\"D3\",'D4',\"D5\",\"A0\",\"A1\"]]\n",
    "\n",
    "    return dataset_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the last state with the exit action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_dataset(dataset_short):\n",
    "    extended_dataset = dataset_short.copy()\n",
    "    exit_state = pd.DataFrame([{\"id_camino\":0,\"D0\":0,'D1':0,\"D2\":0,\"D3\":0,'D4':0,\"D5\":0,\"A0\":-1,\"A1\":-1}])\n",
    "    for camino in extended_dataset[\"id_camino\"].unique():\n",
    "        exit_state[\"id_camino\"] = camino\n",
    "        extended_dataset.append(exit_state)\n",
    "\n",
    "    return extended_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_short = get_data(\"./data/OSPA_training_data 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id_camino         D0         D1         D2        D3        D4  \\\n",
       "0             0  85.591116  -9.250073  -4.257165  0.000000  0.000000   \n",
       "1             0  80.846048  -8.006316  -5.915147 -0.618050  0.228180   \n",
       "2             0  74.575747  -7.229901  -5.983671 -0.806063 -0.238873   \n",
       "3             0  68.915460  -6.614438  -6.322726 -0.403866  0.287311   \n",
       "4             0  62.080447  -5.388121  -6.883976 -0.744963 -0.154067   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "2073        239  33.896035 -30.077869  -7.023492 -0.332507  0.532105   \n",
       "2074        239  26.749762 -23.981863 -11.837088 -0.170587  0.772923   \n",
       "2075        239  17.436739 -13.520295 -16.015517 -0.120340  0.875689   \n",
       "2076        239   4.547199  -2.341143 -17.729530 -0.336825  0.518724   \n",
       "2077        239   0.015317  -0.971868 -16.892517 -1.084577 -0.051936   \n",
       "\n",
       "            D5       A0   A1  \n",
       "0     0.000000 -0.05236  0.0  \n",
       "1     0.002423 -0.10472  0.0  \n",
       "2    -0.012752 -0.00000  0.0  \n",
       "3     0.014920 -0.08727  0.0  \n",
       "4    -0.013679 -0.03491  0.0  \n",
       "...        ...      ...  ...  \n",
       "2073  0.011985 -0.00000  0.0  \n",
       "2074  0.004712 -0.00000  0.0  \n",
       "2075  0.002187 -0.01745  0.0  \n",
       "2076 -0.011393 -0.08727  0.0  \n",
       "2077 -0.063279      NaN  NaN  \n",
       "\n",
       "[2078 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_camino</th>\n      <th>D0</th>\n      <th>D1</th>\n      <th>D2</th>\n      <th>D3</th>\n      <th>D4</th>\n      <th>D5</th>\n      <th>A0</th>\n      <th>A1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>85.591116</td>\n      <td>-9.250073</td>\n      <td>-4.257165</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.05236</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>80.846048</td>\n      <td>-8.006316</td>\n      <td>-5.915147</td>\n      <td>-0.618050</td>\n      <td>0.228180</td>\n      <td>0.002423</td>\n      <td>-0.10472</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>74.575747</td>\n      <td>-7.229901</td>\n      <td>-5.983671</td>\n      <td>-0.806063</td>\n      <td>-0.238873</td>\n      <td>-0.012752</td>\n      <td>-0.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>68.915460</td>\n      <td>-6.614438</td>\n      <td>-6.322726</td>\n      <td>-0.403866</td>\n      <td>0.287311</td>\n      <td>0.014920</td>\n      <td>-0.08727</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>62.080447</td>\n      <td>-5.388121</td>\n      <td>-6.883976</td>\n      <td>-0.744963</td>\n      <td>-0.154067</td>\n      <td>-0.013679</td>\n      <td>-0.03491</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2073</th>\n      <td>239</td>\n      <td>33.896035</td>\n      <td>-30.077869</td>\n      <td>-7.023492</td>\n      <td>-0.332507</td>\n      <td>0.532105</td>\n      <td>0.011985</td>\n      <td>-0.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2074</th>\n      <td>239</td>\n      <td>26.749762</td>\n      <td>-23.981863</td>\n      <td>-11.837088</td>\n      <td>-0.170587</td>\n      <td>0.772923</td>\n      <td>0.004712</td>\n      <td>-0.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2075</th>\n      <td>239</td>\n      <td>17.436739</td>\n      <td>-13.520295</td>\n      <td>-16.015517</td>\n      <td>-0.120340</td>\n      <td>0.875689</td>\n      <td>0.002187</td>\n      <td>-0.01745</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2076</th>\n      <td>239</td>\n      <td>4.547199</td>\n      <td>-2.341143</td>\n      <td>-17.729530</td>\n      <td>-0.336825</td>\n      <td>0.518724</td>\n      <td>-0.011393</td>\n      <td>-0.08727</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2077</th>\n      <td>239</td>\n      <td>0.015317</td>\n      <td>-0.971868</td>\n      <td>-16.892517</td>\n      <td>-1.084577</td>\n      <td>-0.051936</td>\n      <td>-0.063279</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2078 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extended_dataset= extend_dataset(dataset_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      id_camino         D0         D1        D2   D3   D4   D5       A0   A1\n0             0  85.591116  -9.250073 -4.257165  0.0  0.0  0.0 -0.05236  0.0\n15            1  98.043500 -37.779358 -4.257165  0.0  0.0  0.0 -0.03491  0.0\n25            2  91.272922 -36.852284 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n34            3  94.839433  -8.007799 -4.257165  0.0  0.0  0.0 -0.05236  0.0\n52            4  69.791783 -31.305606 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n...         ...        ...        ...       ...  ...  ...  ...      ...  ...\n2042        235  41.074009 -34.144254 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n2048        236  40.754941 -11.474966 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n2054        237  36.542365 -20.220654 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n2059        238  77.290122 -11.950868 -4.257165  0.0  0.0  0.0 -0.03491  0.0\n2072        239  38.729629 -32.034013 -4.257165  0.0  0.0  0.0 -0.00000  0.0\n\n[240 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extended_dataset.loc[extended_dataset[\"D3\"]==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ywmerQ6dSox"
   },
   "source": [
    "It is good practice to normalize features that use different scales and ranges. Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input.\n",
    "\n",
    "Note: Although we intentionally generate these statistics from only the training dataset, these statistics will also be used to normalize the test dataset. We need to do that to project the test dataset into the same distribution that the model has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, train_stats):\n",
    "  #return (x - train_stats['mean']) / train_stats['std']\n",
    "  return (x) / train_stats['std']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x, train_stats):\n",
    "  #return (x - train_stats['mean']) / train_stats['std']\n",
    "  return (x) * train_stats['std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataset_short,action_vector):\n",
    "    reduced_dataset = dataset_short.copy()\n",
    "    reduced_dataset.pop(\"A0\")\n",
    "    reduced_dataset.pop(\"A1\")\n",
    "    reduced_dataset.pop(\"id_camino\")\n",
    "    data_stats = reduced_dataset.describe()\n",
    "    data_stats = data_stats.transpose()\n",
    "\n",
    "    data_stats.to_csv(r\"./data/data_stats2.csv\")\n",
    "\n",
    "    action_vector.append(\"id_camino\")\n",
    "    normed_data = norm(reduced_dataset, data_stats)\n",
    "    normed_dataset = normed_data.join(dataset_short[action_vector])\n",
    "\n",
    "    return normed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(normed_dataset,N_STEPS, position):\n",
    "    PAD_LEN = N_STEPS+1\n",
    "    padded_data = []\n",
    "    for camino in normed_dataset[\"id_camino\"].unique():\n",
    "        group = normed_dataset[normed_dataset[\"id_camino\"]==camino]\n",
    "        group.pop(\"id_camino\")\n",
    "        padded_data.append(group.values)\n",
    "    \n",
    "    dataset2 = tf.keras.preprocessing.sequence.pad_sequences(padded_data, maxlen=PAD_LEN, dtype='float64', padding=position, truncating=position, value=0.0)\n",
    "\n",
    "    return dataset2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pasky': virtualenv)",
   "name": "python37564bitpaskyvirtualenvdb13efe5d4c0467fbbb744965ba97dd5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}