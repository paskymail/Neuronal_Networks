#parametro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
#CONSTRUCCION DEL BOSQUE ALEATORIO
#Se contruyen 500 Arboles y se obtiene la clasificacion mas votada. Cada uno de los
#Arboles se contruyen eligiendo entre m=sqrt(16)=4 variables predictoras en cada
#nodo
RF<- randomForest(out_action ~ ., data=actionent, importance=TRUE,do.trace=TRUE)
RF
plot(RF)
# La muestras no utilizadas en los conjuntos bootstrap (Out of bag) se utilizan como
#conjunto test para clacular el error del modelo.
legend("topright",col=1:3,lty=1:3,
legend=c("OOB",levels(Rset$lettr)))
grid()
varImpPlot(RF)
#Aqui obtenemos la importacia de la variable
importancias=importance(RF)
#Comparandolas con las del arbol3 de clasificacion, vemos que no coinciden
#exactamente las variables mas importantes. Esto es debido a la poca estabilidad de
#la solucion de calcular un unico Arbol (Arbol3)
cbind(action.rpart$variable.importance)
round(cbind(importancias[order(-importancias[,3]),3]),2)
predictest<- predict(RF,newdata=Rset[-indient,], type="response")
ctRF<-table(Rset[-indient,"out_action"],predictest)
ctRF
# ACIERTO POR GRUPOS
100*diag(prop.table(ctRF, 1))
# ACIERTO TOTAL
TPCRF <- 100*sum(diag(prop.table(ctRF)))
#Curva COR
library(ROCR)
probabi<- predict(RF,newdata=Rset[-indient,],
type="prob")[,2]
prediobj<-prediction(probabi,Rset[-indient,"out_action"])
plot(performance(prediobj, "tpr","fpr"),
main="CURVA COR TEST, RF")
abline(a=0,b=1,col="blue",lty=2)
aucRF<- as.numeric(performance(prediobj,"auc")@y.values)
cat("AUC test= ",aucRF ,"\n")
# Podemos observar que el error en el conjunto test del Random Forest es bastante
#menor que el del Arbol 3, debido a que estamos utilizando la clasificacion
#mas votada de un conjunto de 500 Arboles.
# Podemos tambien observar que dicha diferencia coincide en valor (7%) con la
#disminucion del error que se observa en el grafico "error vs numero de Arboles",
#como era de esperar.
Comp2 <- matrix(c(TPC3,auc3, TPCRF, aucRF),ncol=2,byrow=TRUE)
colnames(Comp2) <- c("Total % correcto","AUC")
rownames(Comp2) <- c("Arbol3","RF")
Comp2
knitr::opts_chunk$set(echo = TRUE)
#install.packages("xlsx")
library(xlsx)
#Cargamos el dataframe
actionset <- read.xlsx("fromStateToAction_RF_norm.xlsx",
sheetIndex = 1)
#estudiamos sus variables
summary(actionset)
#install.packages("xlsx")
library(xlsx)
#Cargamos el dataframe
actionset <- read.xlsx("fromStateToAction_RF_norm.xlsx",
sheetIndex = 1)
#estudiamos sus variables
summary(actionset)
Rset <-actonset
library(kernlab)
library(randomForest)
# Obtenemos el modelo RF sobre el conjunto de entrenamiento.
# Tambien podrÃ�amos haber usado directamente data =actiontest y utillizar el
#parametro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
#CONSTRUCCION DEL BOSQUE ALEATORIO
#Se contruyen 500 Arboles y se obtiene la clasificacion mas votada. Cada uno de los
#Arboles se contruyen eligiendo entre m=sqrt(16)=4 variables predictoras en cada
#nodo
RF<- randomForest(out_action ~ ., data=actionent, importance=TRUE,do.trace=TRUE)
RF
plot(RF)
# La muestras no utilizadas en los conjuntos bootstrap (Out of bag) se utilizan como
#conjunto test para clacular el error del modelo.
legend("topright",col=1:3,lty=1:3,
legend=c("OOB",levels(Rset$out_action)))
grid()
varImpPlot(RF)
#Aqui obtenemos la importacia de la variable
importancias=importance(RF)
#Comparandolas con las del arbol3 de clasificacion, vemos que no coinciden
#exactamente las variables mas importantes. Esto es debido a la poca estabilidad de
#la solucion de calcular un unico Arbol (Arbol3)
cbind(action.rpart$variable.importance)
round(cbind(importancias[order(-importancias[,3]),3]),2)
predictest<- predict(RF,newdata=Rset[-indient,], type="response")
ctRF<-table(Rset[-indient,"out_action"],predictest)
ctRF
# ACIERTO POR GRUPOS
100*diag(prop.table(ctRF, 1))
# ACIERTO TOTAL
TPCRF <- 100*sum(diag(prop.table(ctRF)))
#Curva COR
library(ROCR)
probabi<- predict(RF,newdata=Rset[-indient,],
type="prob")[,2]
prediobj<-prediction(probabi,Rset[-indient,"out_action"])
plot(performance(prediobj, "tpr","fpr"),
main="CURVA COR TEST, RF")
abline(a=0,b=1,col="blue",lty=2)
aucRF<- as.numeric(performance(prediobj,"auc")@y.values)
cat("AUC test= ",aucRF ,"\n")
# Podemos observar que el error en el conjunto test del Random Forest es bastante
#menor que el del Arbol 3, debido a que estamos utilizando la clasificacion
#mas votada de un conjunto de 500 Arboles.
# Podemos tambien observar que dicha diferencia coincide en valor (7%) con la
#disminucion del error que se observa en el grafico "error vs numero de Arboles",
#como era de esperar.
Comp2 <- matrix(c(TPC3,auc3, TPCRF, aucRF),ncol=2,byrow=TRUE)
colnames(Comp2) <- c("Total % correcto","AUC")
rownames(Comp2) <- c("Arbol3","RF")
Comp2
#install.packages("xlsx")
library(xlsx)
#Cargamos el dataframe
actionset <- read.xlsx("fromStateToAction_RF_norm.xlsx",
sheetIndex = 1)
#estudiamos sus variables
summary(actionset)
Rset <- actonset
#install.packages("xlsx")
library(xlsx)
#Cargamos el dataframe
actionset <- read.xlsx("fromStateToAction_RF_norm.xlsx",
sheetIndex = 1)
#estudiamos sus variables
summary(actionset)
Rset <- actionset
library(kernlab)
library(randomForest)
# Obtenemos el modelo RF sobre el conjunto de entrenamiento.
# Tambien podrÃ�amos haber usado directamente data =actiontest y utillizar el
#parametro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
#CONSTRUCCION DEL BOSQUE ALEATORIO
#Se contruyen 500 Arboles y se obtiene la clasificacion mas votada. Cada uno de los
#Arboles se contruyen eligiendo entre m=sqrt(16)=4 variables predictoras en cada
#nodo
RF<- randomForest(out_action ~ ., data=actionent, importance=TRUE,do.trace=TRUE)
RF
plot(RF)
# La muestras no utilizadas en los conjuntos bootstrap (Out of bag) se utilizan como
#conjunto test para clacular el error del modelo.
legend("topright",col=1:3,lty=1:3,
legend=c("OOB",levels(Rset$out_action)))
grid()
varImpPlot(RF)
#Aqui obtenemos la importacia de la variable
importancias=importance(RF)
#Comparandolas con las del arbol3 de clasificacion, vemos que no coinciden
#exactamente las variables mas importantes. Esto es debido a la poca estabilidad de
#la solucion de calcular un unico Arbol (Arbol3)
cbind(action.rpart$variable.importance)
round(cbind(importancias[order(-importancias[,3]),3]),2)
predictest<- predict(RF,newdata=Rset[-indient,], type="response")
ctRF<-table(Rset[-indient,"out_action"],predictest)
ctRF
# ACIERTO POR GRUPOS
100*diag(prop.table(ctRF, 1))
# ACIERTO TOTAL
TPCRF <- 100*sum(diag(prop.table(ctRF)))
#Curva COR
library(ROCR)
probabi<- predict(RF,newdata=Rset[-indient,],
type="prob")[,2]
prediobj<-prediction(probabi,Rset[-indient,"out_action"])
library(kernlab)
library(randomForest)
# Obtenemos el modelo RF sobre el conjunto de entrenamiento.
# Tambien podrÃ�amos haber usado directamente data =actiontest y utillizar el
#parametro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
#CONSTRUCCION DEL BOSQUE ALEATORIO
#Se contruyen 500 Arboles y se obtiene la clasificacion mas votada. Cada uno de los
#Arboles se contruyen eligiendo entre m=sqrt(16)=4 variables predictoras en cada
#nodo
RF<- randomForest(out_action ~ ., data=actionent, importance=TRUE,do.trace=TRUE)
RF
plot(RF)
# La muestras no utilizadas en los conjuntos bootstrap (Out of bag) se utilizan como
#conjunto test para clacular el error del modelo.
legend("topright",col=1:3,lty=1:3,
legend=c("OOB",levels(Rset$out_action)))
grid()
varImpPlot(RF)
#Aqui obtenemos la importacia de la variable
importancias=importance(RF)
#Comparandolas con las del arbol3 de clasificacion, vemos que no coinciden
#exactamente las variables mas importantes. Esto es debido a la poca estabilidad de
#la solucion de calcular un unico Arbol (Arbol3)
cbind(action.rpart$variable.importance)
round(cbind(importancias[order(-importancias[,3]),3]),2)
predictest<- predict(RF,newdata=Rset[-indient,], type="response")
ctRF<-table(Rset[-indient,"out_action"],predictest)
ctRF
# ACIERTO POR GRUPOS
100*diag(prop.table(ctRF, 1))
# ACIERTO TOTAL
TPCRF <- 100*sum(diag(prop.table(ctRF)))
#Curva COR
#library(ROCR)
#probabi<- predict(RF,newdata=Rset[-indient,],
#                  type="prob")[,2]
#prediobj<-prediction(probabi,Rset[-indient,"out_action"])
#plot(performance(prediobj, "tpr","fpr"),
#     main="CURVA COR TEST, RF")
#abline(a=0,b=1,col="blue",lty=2)
#aucRF<- as.numeric(performance(prediobj,"auc")@y.values)
#cat("AUC test= ",aucRF ,"\n")
# Podemos observar que el error en el conjunto test del Random Forest es bastante
#menor que el del Arbol 3, debido a que estamos utilizando la clasificacion
#mas votada de un conjunto de 500 Arboles.
# Podemos tambien observar que dicha diferencia coincide en valor (7%) con la
#disminucion del error que se observa en el grafico "error vs numero de Arboles",
#como era de esperar.
#Comp2 <- matrix(c(TPC3,auc3, TPCRF, aucRF),ncol=2,byrow=TRUE)
#colnames(Comp2) <- c("Total % correcto","AUC")
#rownames(Comp2) <- c("Arbol3","RF")
#Comp2
knitr::opts_chunk$set(echo = TRUE)
#Elegimos dos acciones aleatorias
Actions <- c(0:2)
Actions
#Elegimos dos acciones aleatorias
Actions <- c(0:27)
Actions
#install.packages("xlsx")
library(xlsx)
#Cargamos el dataframe
actionset <- read.xlsx("fromStateToAction_RF_norm.xlsx",
sheetIndex = 1)
#estudiamos sus variables
summary(actionset)
#Elegimos dos acciones aleatorias
Actions <- c(0:27)
Actions
# reducimos actionset a los casos que se corresponden con alguna de las acciones
Rset <- subset(actionset, actionset$out_action %in% Actions)
# Eliminamos de los niveles del factor Rset$lettr las letras no seleccionadas
Rset$out_action <- droplevels.factor(Rset$out_action)
# Comprobamos que hemos hecho la reducciÃ³n correctamente
dim(Rset)
summary(Rset$out_action)
# Dividimos el conjunto Rset en subconjunto de entrenammiento 70% y test 30%
n<- nrow(Rset)
nent<- ceiling(0.7*n)
ntest<- n-nent
indin<- 1:n
set.seed(12345)
# Se hace un sampling aleatorio de los Ã�ndices de las filas de Rset eligiendo nest
#muestras sin replazamiento
indient<- sort(sample(indin,nent))
# El resto de indices de filas no elgidas serÃ¡n la muestra de test
inditest<- setdiff(indin,indient)
#Conjuntos de entrenamiento y test en base a los Ã�ndices de fila elegidos
actionent<- Rset[indient,]
actiontest<- Rset[inditest,]
library(rpart)
# Obtenemos el modelo de Arbol de clasificacion sobre el conjunto de entrenamiento
# TambiÃen podriamos haber usado directamente data =lettertest y utillizar el
#parÃ¡metro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
action.rpart <- rpart(out_action ~ ., data=actionent, method="class")
#Utilizamos el codigo del script del tema7 para obtener la tabla de contingencia y
#la curva "Receiver Operating Characteristic"
plot(action.rpart,main="CART datos action prediction",uniform=TRUE)
text(action.rpart,col="blue",cex=0.7)
#Usamos el modelo para predecir el conjunto test
predictest<- predict(action.rpart,actiontest, type="class")
#Creamos la tabla de contingencia de predicciones vs letra real
ct1<-table(actiontest$out_action,predictest)
ct1
# ACIERTO POR GRUPOS
100*diag(prop.table(ct1, 1))
# ACIERTO TOTAL
TPC1 <- 100*sum(diag(prop.table(ct1)))
TPC1
#VALIDACION CRUZADA, REGLA 1-SE
#rpart calcula para una secuencia de subÃ¡rboles anidados una estimaciÃ³n del error de
#clasificaciÃ³n mediante validaciÃ³n cruzada.
#Se utiliza la regla 1-SE para tener en cuenta la variabilidad del proceso de
#selcciÃ³n de variable en el nodo junto con el error de validaciÃ³n cruzada
printcp(action.rpart,digits=3)
#Se reduce el valor de cp como criterio de parada de cp=0.01 (defaut) a cp=0.001
#para obtener un Ã¡rbol con exceso de ramificaciones para despuÃ©s podarlo mediante la
#regal 1-SE:
action.rpart2 <- rpart(out_action ~ ., data=actionent, method="class",cp=0.001)
action.rpart2
plot(action.rpart2,main="CART datos action. CP=0.001",uniform=TRUE)
text(action.rpart2,col="blue",cex=0.6)
printcp(action.rpart2,digits=3)
plotcp(action.rpart2)
plotcp(action.rpart2,lty=2,upper="splits",col="blue")
#Tabla con las estimaciones VC
cptabla<- action.rpart2$cptable
#Sobre el conjunto test
ct2<-table(actiontest$out_action,predict(action.rpart2,actiontest,type="class"))
ct2
# Porcentaje correcto por grupos
100*diag(prop.table(ct2, 1))
# total porcentaje correcto
TPC2 <- 100*sum(diag(prop.table(ct2)))
TPC2
#Regla 1-ES : tomamos el menor sub-Ã¡rbol tal que el error de validaciÃ³n cruzada es
#menor que el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
#calcualamos el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
CP1ES<- min(cptabla[,4])+cptabla[which.min(cptabla[,4]),5]
CP1ES
#localizamos el valor de CP del sub-Ã¡rbol tal que el error de validaciÃ³n cruzada es
#menor que el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
indicp<- 1:nrow(cptabla)
cprecorte<- cptabla[indicp[cptabla[,4]<CP1ES][1],1]
cprecorte
#Obtenemos el sub-Ã¡rbol correspondiente a dicho CP mediante el recorte
action.rpart3<-prune.rpart(action.rpart2,cp=cprecorte)
action.rpart3
plot(action.rpart3,main="CART recortado",uniform=TRUE)
text(action.rpart3,col="blue",cex=0.6)
#Sobre el conjunto test
ct3<-table(actiontest$out_action,predict(action.rpart3,actiontest,type="class"))
ct3
# Porcentaje correcto por grupos
100*diag(prop.table(ct3, 1))
# total porcentaje correcto
TPC3 <- 100*sum(diag(prop.table(ct3)))
TPC3
#Curva COR
probabi<- predict(action.rpart3,actiontest,type="prob")[,2] #Prob. yes
prediobj<-prediction(probabi,actiontest$out_action)
library(rpart)
# Obtenemos el modelo de Arbol de clasificacion sobre el conjunto de entrenamiento
# TambiÃen podriamos haber usado directamente data =lettertest y utillizar el
#parÃ¡metro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
action.rpart <- rpart(out_action ~ ., data=actionent, method="class")
#Utilizamos el codigo del script del tema7 para obtener la tabla de contingencia y
#la curva "Receiver Operating Characteristic"
plot(action.rpart,main="CART datos action prediction",uniform=TRUE)
text(action.rpart,col="blue",cex=0.7)
#Usamos el modelo para predecir el conjunto test
predictest<- predict(action.rpart,actiontest, type="class")
#Creamos la tabla de contingencia de predicciones vs letra real
ct1<-table(actiontest$out_action,predictest)
ct1
# ACIERTO POR GRUPOS
100*diag(prop.table(ct1, 1))
# ACIERTO TOTAL
TPC1 <- 100*sum(diag(prop.table(ct1)))
TPC1
#VALIDACION CRUZADA, REGLA 1-SE
#rpart calcula para una secuencia de subÃ¡rboles anidados una estimaciÃ³n del error de
#clasificaciÃ³n mediante validaciÃ³n cruzada.
#Se utiliza la regla 1-SE para tener en cuenta la variabilidad del proceso de
#selcciÃ³n de variable en el nodo junto con el error de validaciÃ³n cruzada
printcp(action.rpart,digits=3)
#Se reduce el valor de cp como criterio de parada de cp=0.01 (defaut) a cp=0.001
#para obtener un Ã¡rbol con exceso de ramificaciones para despuÃ©s podarlo mediante la
#regal 1-SE:
action.rpart2 <- rpart(out_action ~ ., data=actionent, method="class",cp=0.001)
action.rpart2
plot(action.rpart2,main="CART datos action. CP=0.001",uniform=TRUE)
text(action.rpart2,col="blue",cex=0.6)
printcp(action.rpart2,digits=3)
plotcp(action.rpart2)
plotcp(action.rpart2,lty=2,upper="splits",col="blue")
#Tabla con las estimaciones VC
cptabla<- action.rpart2$cptable
#Sobre el conjunto test
ct2<-table(actiontest$out_action,predict(action.rpart2,actiontest,type="class"))
ct2
# Porcentaje correcto por grupos
100*diag(prop.table(ct2, 1))
# total porcentaje correcto
TPC2 <- 100*sum(diag(prop.table(ct2)))
TPC2
#Regla 1-ES : tomamos el menor sub-Ã¡rbol tal que el error de validaciÃ³n cruzada es
#menor que el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
#calcualamos el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
CP1ES<- min(cptabla[,4])+cptabla[which.min(cptabla[,4]),5]
CP1ES
#localizamos el valor de CP del sub-Ã¡rbol tal que el error de validaciÃ³n cruzada es
#menor que el error de validaciÃ³n cruzada mÃ�nimo + su desviaciÃ³n tÃ�pica
indicp<- 1:nrow(cptabla)
cprecorte<- cptabla[indicp[cptabla[,4]<CP1ES][1],1]
cprecorte
#Obtenemos el sub-Ã¡rbol correspondiente a dicho CP mediante el recorte
action.rpart3<-prune.rpart(action.rpart2,cp=cprecorte)
action.rpart3
plot(action.rpart3,main="CART recortado",uniform=TRUE)
text(action.rpart3,col="blue",cex=0.6)
#Sobre el conjunto test
ct3<-table(actiontest$out_action,predict(action.rpart3,actiontest,type="class"))
ct3
# Porcentaje correcto por grupos
100*diag(prop.table(ct3, 1))
# total porcentaje correcto
TPC3 <- 100*sum(diag(prop.table(ct3)))
TPC3
# Podemos comparar el Arbol1 seleccionado automÃ¡ticamente por la funciÃ³n Rpart con
#el Arbol3 elegido mediante la regla 1-SE y el Arbol2 sin recorte.
# Podemos ver que, como esperado, el Ã¡rbol 2 (sin recorte) tiene el menor error
#Esto se obtiene como contrapartida a un sobre-ajuste.
#TambiÃ©n vemos que el Arbol1 tiene menos nodos y mayor error que el Arbol3. Esto se
#debe a que en el Arbol1 hemos llegado a la condiciÃ³n de parada (CP=0.01) con 8
#nodos, mucho antes de los necesarios para alcanzar el error de validaciÃ³n currzada
#minimo (14 nodos).
Comp <- matrix(c(TPC1,auc1,TPC2,auc2, TPC3,auc3),ncol=2,byrow=TRUE)
colnames(Comp) <- c("Total % correcto","AUC")
rownames(Comp) <- c("Arbol1","arbol2","arbol3")
Comp
#LA SIGUIENTE FUNCION PERMITE GENERAR LAS DISTINTAS REGLAS DE CLASIFICACION
#A PARTIR DEL OBJETO RESULTANTE DE rpart
list.rules.rpart <- function(model)
{
if (!inherits(model, "rpart")) stop("No es una objeto rpart")
#
#
#
frm     <- model$frame
names   <- row.names(frm)
ylevels <- attr(model, "ylevels")
ds.size <- model$frame[1,]$n
#
# Print each leaf node as a rule.
#
numreglas=0
for (i in 1:nrow(frm))
{
if (frm[i,1] == "<leaf>")  #Nodos terminales
{
numreglas=numreglas+1
cat("\n")
cat(sprintf(" Regla nÃºmero: %s (nodo %s) ", numreglas,names[i]))
cat(sprintf("[yval=%s cover=%d (%.0f%%) prob=%0.2f]\n",
ylevels[frm[i,]$yval], frm[i,]$n,
round(100*frm[i,]$n/ds.size), frm[i,]$yval2[,5]))
pth <- path.rpart(model, nodes=as.numeric(names[i]), print.it=FALSE)
cat(sprintf("   %s\n", unlist(pth)[-1]), sep="")
}
}
}
list.rules.rpart(action.rpart3)
plot(action.rpart3,main="CART recortado",uniform=TRUE)
text(action.rpart3,col="blue",cex=0.6)
list.rules.rpart(action.rpart)
plot(action.rpart,main="CART recortado",uniform=TRUE)
text(action.rpart,col="blue",cex=0.6)
#DIBUJAR EL ARBOL CON CON partykit
library(partykit)
rpart1 <- as.party(action.rpart)
plot(rpart1)
#LA NUMERACION DE LOS NODOS PUEDE DIFERIR CON rpart
#PARA ARBOLES GRANDES, COMO rpart3, NO SE APRECIA BIEN
#IMPORTANCIA DE LAS VARIABLES
######################################
#La variables mÃ¡s importantes son aquellas que contribuyen a disminuir la impureza
#en mayor medida. Debido a la poca estabilidad de los modelos, se utiliza no sÃ³lo la
#disminuciÃ³n de impureza de la variable cuando es elegida en un nodo, sino tambiÃ©n
#su contribuciÃ³n como variable sustituta.
#Aparece en la salida de summary:
#summary(action.rpart)
#o bien
cbind(action.rpart$variable.importance)
library(kernlab)
library(randomForest)
# Obtenemos el modelo RF sobre el conjunto de entrenamiento.
# Tambien podrÃ�amos haber usado directamente data =actiontest y utillizar el
#parametro subset para indicar que solo usaremos el subconjunto definido por los
#indices de fila indient (subset= indient)
#CONSTRUCCION DEL BOSQUE ALEATORIO
#Se contruyen 500 Arboles y se obtiene la clasificacion mas votada. Cada uno de los
#Arboles se contruyen eligiendo entre m=sqrt(16)=4 variables predictoras en cada
#nodo
RF<- randomForest(out_action ~ ., data=actionent, importance=TRUE,do.trace=TRUE)
RF
plot(RF)
# La muestras no utilizadas en los conjuntos bootstrap (Out of bag) se utilizan como
#conjunto test para clacular el error del modelo.
legend("topright",col=1:3,lty=1:3,
legend=c("OOB",levels(Rset$out_action)))
grid()
varImpPlot(RF)
#Aqui obtenemos la importacia de la variable
importancias=importance(RF)
#Comparandolas con las del arbol3 de clasificacion, vemos que no coinciden
#exactamente las variables mas importantes. Esto es debido a la poca estabilidad de
#la solucion de calcular un unico Arbol (Arbol3)
cbind(action.rpart$variable.importance)
round(cbind(importancias[order(-importancias[,3]),3]),2)
predictest<- predict(RF,newdata=Rset[-indient,], type="response")
ctRF<-table(Rset[-indient,"out_action"],predictest)
ctRF
# ACIERTO POR GRUPOS
100*diag(prop.table(ctRF, 1))
# ACIERTO TOTAL
TPCRF <- 100*sum(diag(prop.table(ctRF)))
# Podemos observar que el error en el conjunto test del Random Forest es bastante
#menor que el del Arbol 3, debido a que estamos utilizando la clasificacion
#mas votada de un conjunto de 500 Arboles.
# Podemos tambien observar que dicha diferencia coincide en valor (7%) con la
#disminucion del error que se observa en el grafico "error vs numero de Arboles",
#como era de esperar.
Comp2 <- matrix(c(TPC3,auc3, TPCRF, aucRF),ncol=2,byrow=TRUE)
colnames(Comp2) <- c("Total % correcto","AUC")
rownames(Comp2) <- c("Arbol3","RF")
Comp2
